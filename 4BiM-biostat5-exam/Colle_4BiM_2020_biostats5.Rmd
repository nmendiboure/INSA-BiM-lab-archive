---
title: "Colle_4BiM_2020_biostats5"
author: "Nicolas Mendiboure 4BiM"
date: "29/01/2021"
geometry: margin=2cm
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r clean variables}
rm(list=ls())
```

```{r datas loading}
goodlife <- read.csv("./good_life.txt", sep = "\t", header = TRUE, dec = ",")
continent <- goodlife$continent
region <- goodlife$region_monde
pays <- goodlife$pays
co2 <- goodlife$CO2
eau <- goodlife$eau
sanitaire <- as.factor(goodlife$sanitaire)
democratie <- as.factor(goodlife$democratie)
```

### Q1. Les variables « sanitaire » et « democratie » sont-elles dépendantes ? Justifier votre réponse par un test approprié et exprimer la conclusion avec une phrase complète.

```{r lm1}
num_sanitaire <- as.numeric(sanitaire)
num_democratie <- as.numeric(democratie)
tab <- table(num_sanitaire,num_democratie)
chisq.test(tab)
```
On fait une table de contingence que l'on nomme *tab* avec les effectifs observés pour nos 2 variables « sanitaire » et « democratie ». Les deux variables sont converties préalablement en variables numériques. On effectue un test de chisq2 en comparant nos effectifs observés à nos effectifs théoriques.

H0 : Les variables « sanitaire » et « democratie » sont indépendantes;

H1 : Les variables « sanitaire » et « democratie » sont dépendantes.

On effectue le test du chisq2 et nous obtenons une p-value de 9.844e-06 donc très significative, ce qui nous permet de rejeter H0.
Il existe une relation qui lie la variable « sanitaire » à la variable  « democratie ». Autrement dit, l'état sanitaire varie lorsque que le niveau de démocratie varie.

Remarque : Il faut faire attention à la condition d'utilisation pour le test du chisq2. Celle ci dit qu'il faut vérifier que 80% des classes aient  un effectif théorique supérieure ou égale à 5. 

On peut vérifier cela de la façon suivante :

```{r khideux expected}
chisq.test(tab)$expected
```

La condition est donc bien vérifiée. Dans le cas contraire il faudrait utiliser le test exact de *fisher* comme ci dessous :

```{r fisher.test}
fisher.test(tab)
```

### Q2. Décrire le plan d’expérience correspondant à l’analyse demandée.

```{r Q2}
xtabs(~ sanitaire + democratie)
```
Grâce à la fonction xtabs ci-dessus, on voit qu'il s'agit d'un plan d'expérience factoriel croisé à deux facteurs (democratie 3 niveaux et sanitaire 2 niveaux) car pour chaque couple (*sanitaire[i]*, *democratie[j]*) nous avons des mesures de CO2. Le plan est également complet car nous n'avons pas de case vide, mais il est déséquilibré car nous n'avons pas le même nombre de mesures par case. Il s'agit d'un modèle fixe car nos 2 variables explicatives sont fixes. Pour justifier cela nous pouvons dire tout simplement que les différents niveaux des variables ont été sélectionnés et contrôlés pour effectuer cette étude.


### Q3. Comparer les émissions de CO2 des pays en fonction de leur niveau de démocratie et de leur état sanitaire par un modèle (lm1) et réaliser les tests appropriés ?

Dans la question 1 nous avons vu que nous devions rejeter l'hypothèse disant que les variables *sanitaire* et *democratie* étaient indépendante. Nous savons donc qu'il existe une interaction entre ces 2 variables, mais nous ne savons pas si cette interaction a un effet significatif sur les émissions de C02. On peut tout d'abord commencer par donner un aperçu de cette interaction afin d'avoir un idée : 

```{r interaction plot}
interaction.plot(sanitaire, democratie, co2, col = 2:4)
```


Nous allons maintenant construire un premier modèle linéaire qui prendra en compte cette interaction :

```{r Q3}
lm1 <- lm(co2 ~ democratie * sanitaire )
coefficients(lm1)
anova(lm1)
```
Après avoir fait un test d'anova on se rend compte que le terme d'interaction n'est pas significatif (p-value = 0.3). Ce tableau permet également de tester les effets du niveau de démocratie et de l'état sanitaire sur l'émission de CO2.

Les effets *democratie* et *sanitaire* sont tous les deux très significatif. Ainsi il y aurait globalement une différence d'émission de CO2 d'un niveau de démocratie à un autre, de plus le taux d'émission dans un état sanitaire bas serait globalement moins élevé que dans un état sanitaire haut (coefficient *sanitairehaut* positif, *sanitairebas* dans l'intercepte).

On a vu que le terme d'interaction n'était pas significatif, nous pouvons donc l'enlever de notre modèle *lm1*. Ce raisonnement n'est toutefois pas le meilleur car si l'on veut tester les termes par rapport au terme d'interaction, celui-ci ayant été retiré se trouvera dans la résiduelle.

```{r new lm1}
lm1b <- lm(co2~ democratie + sanitaire)
summary(lm1b)
```

Grâce au *summary* on voit que les effets de  *democratiefort* et de *sanitairehaut* haut diffèrent de *democratiebas* et *sanitairebas*. Il est possible de faire un contraste pour tester *democratiefort* et *democratiemoyen* :

```{r contrast}
contrasts(democratie) #par défaut
democratie2 <- democratie
contrasts(democratie2) <- contr.treatment(3, base = 2)
contrasts(democratie2) # democratiefort passe en référence (dans l'intercept)
lm1c <- lm(co2~democratie2+sanitaire)
summary(lm1c)
```
On voit donc qu'il y a une différence de moyenne d'émission de co2 entre *democratiefort* (maintenant dans l'intercept) et *democratiemoyen*.

### Q4. Ecrire le modèle lm1 sous la forme d’une équation et interpréter les termes significatifs.

```{r summary(lm1)}
summary(lm1)
```


L'équation du modèle *lm1* s'écrit :

$Y = \beta_0 + \beta_1 \times I[democratiefort] + \beta_2 \times I[democratiemoyen] + \beta_3 \times I[sanitairehaut] \beta_4 \times I[democratiefort] \times I[sanitairehaut]  + \beta_5 \times I[democratiemoyen] \times I[sanitairehaut] + \epsilon$

-$\beta_0$ correspond à l'intercepte, c'est à dire à la valeur prédite d'émission de co2 pour un niveau de démocratie faible et un état sanitaire bas. Cette valeur n'est pas significative ;

-$\beta_1$ correspond à la différence de moyenne d'émission de co2 pour pour un niveau de démocratie fort et un niveau de démocratie faible, pour un même état sanitaire bas. Ce coefficient est significatif ;

-$\beta_2$ correspond à la différence de moyenne d'émission de co2 pour pour un niveau de démocratie moyen et un niveau de démocratie faible, pour un même état sanitaire bas. Ce coefficient n'est pas significatif ;

-$\beta_3$ correspond à la différence de moyenne d'émission de co2 pour pour un état sanitaire haut et un état sanitaire bas, pour un même niveau de démocratie faible. Ce coefficient est très significatif.

-$\beta4$ correspond à la fois à la différence de moyenne entre les niveaux de démocratie bas et fort et les états sanitaires bas et haut. Il n'est pas significatif.

-$\beta5$ correspond à la fois à la différence de moyenne entre les niveaux de démocratie bas et moyen et les états sanitaires bas et haut. Il n'est pas significatif.

-$\epsilon$ correspond aux résidus que le modèle n'explique pas. 


### Q5. Changer l’ordre d’introduction des variables explicatives de votre modèle ? Quels effets observez-vous sur votre analyse (lm2) et pourquoi ?

```{r q5}
lm2 <- lm(co2 ~ sanitaire * democratie)
coefficients(lm2)
anova(lm2)
```
Les estimations des coefficients sont identiques à celles du premier modèle car les mêmes termes ont été introduits. Ainsi les prédictions du modèle sont les mêmes, et leur sommes des carrés des écarts expliqués par le modèle ainsi que celle de la résiduelle sont identiques. 

En effet la somme des carrés des écarts totale est la même quel que soit le modèle, puisqu’elle correspond à la somme des carrés des écarts entre valeurs observées et moyenne générale : $SCE_T = SCE_M + SCE_R$ . La $SCE_R$ étant identique pour les trois modèles, ceci explique pourquoi la $SCE_M$ est également identique.

En revanche, les analyses de la variance diffèrent, et la répartition des sommes des carrés des écarts expliqués par le modèle entre les facteurs diffère. La somme des carrés des écarts dues à l’intéraction ne varie pas, mais celles des deux facteurs *sanitaire* et *democratie* changent, et leurs variations du modèle *lm1* au modèle *lm2* se compensent.

Dans les plan équilibrés, les termes de sommes des produits sont nuls. Dans un plan déséquilibré comme le notre, il peuvent ne pas être nuls et donc impacter les résultats de l'anova. Dans un cas comme celui-ci ces facteurs de somme des produits sont affectés au différents facteurs existants comme *sanitaire*, *democratie* ou même à l'interaction lorsqu'elle est introduite dans le modèle, et ce suivant l'ordre dans lequel nous introduisant les facteurs dans le modèle. 

En résumé :  Les sommes des carrés ne sont pas identiques car nous avons un plan déséquilibré, ainsi les décompositions en carré ne sont pas indépendantes à cause du déséquilibre.

### Q6. Proposer une solution pour avoir des estimations correctes de votre décomposition de la variance et refaire les conclusions de l’analyse.

Dans le modèle lm1 la somme des carrés de écarts pour le facteur *democratie* qui est introduit en tout premier, est égale à celle lorsque *democratie* est introduit seul dans le modèle. Cette somme est le résultat de la variabilité expliquée par le facteur *democratie* mais aussi des sommes des produits associées aux 2 facteurs. 

Dans le modèle 2, c'est le même raisonnement pour le facteur *sanitaire*. La somme des carrés des écarts de *sanitaire* dans lm2 et la même que lorsqu'on l'introduit seul dans le modèle. Cette somme est donc l'ensemble de la variabilité expliquée par *sanitaire* et par les sommes des produits. 

Ainsi en créant des modèles de références comme ci-dessous, nous pourrons les comparer 2 à 2 dans des tests anova (test des modèles emboités), cela permettra de ne retenir que l'effet d'un facteur, et de s'affranchir des sommes des produits habituellement affectées à ce facteur.

Voici les 6 modèles que nous utiliserons pour cela :

```{r modèles deréférence }
lm1 <- lm(co2 ~ democratie*sanitaire)
lm1b <- lm(co2 ~ democratie + sanitaire)
lm2 <- lm(co2 ~ sanitaire * democratie)
lm2b <- lm(co2 ~ sanitaire + democratie)
lm_democratie <- lm(co2 ~ democratie)
lm_sanitaire <- lm(co2 ~ sanitaire )
```

Pour obtenir l'effet du facteur *democratie* nous allons comparer les modèles *lm2b* et *lm_sanitaire* :

```{r effet democratie :}
anova(lm2b, lm_sanitaire)
```

Pour obtenir l'effet du facteur *sanitaire* nous allons comparer les modèles *lm1b* et *lm_democratie* :

```{r effet sanitaire :}
anova(lm1b, lm_democratie)
```
Pour obtenir l'effet de l'interaction, deux possibilités : en comparant lm1 à lm1b ou e comparant lm2 à lm2b. Vous verrez que les résultats d'anova sont les mêmes.

```{r effet interaction :}
anova(lm1, lm1b)
anova(lm2, lm2b)
```
Pour conclure nous pouvons dire qu'il existe réellement un effet globale de l'état sanitaire d'un pays mais aussi du niveau de démocratie de celui-ci.


Remarque : Ce que nous avons fait à la main jusqu'ici est en fait rien de plus que la somme des carrés des écarts  de type II. Par défaut R fournit les sommes des carrés des écarts de type I lors des tests de variances anova classiques. Cependant les sommes de carrés des écarts de type II peuvent être obtenues à partir de la fonction Anova du la librairie "car" comme ci dessous :

```{r car, message=FALSE}
library(car)
```
```{r anova type II}
Anova(lm1, type = 2)
Anova(lm2, type = 2)
```

On tombe bien sur la même décomposition des variances pour lm1 et pour lm2. 


### Q7. Vérifier les hypothèses associées au premier modèle (lm1) et décrire les problèmes associés.

Les hypothèses à vérifier sont l'égalité des variances entre les différents groupes, la normalité des distributions par groupe, on suppose que les mesures sont indépendantes car effectuées sur des pays différents et qu'il n'y a pas de points aberrants. Enfin on suppose l'existence d'une relation réelle entre l'émission de CO2 et les niveaux de démocraties ainsi que les états sanitaires des pays.

```{r hypothèses q7}
par(mfrow = c(2, 2))
plot(lm1)
```
Sur le premier graphique (haut gauche) on voit une légère forme en 'cloche' pour les résidus, de plus l'espérance des résidus est proche de 0 mais n'est pas nulle. On peut alors se demander si le modèle est bien adapté ? 

Sur le graphique en haut à droite, là aussi il est difficile de dire si les résidus suivent une li normale ou non, le mieux est de faire un test de normalité, *shapiro-wilk* par exemple :

```{r shapiro-wilk}
shapiro.test(residuals(lm1))
```
On a une p-value très significative qui nous permet de rejeter H0 et de conclure à la non normalité des résidus.

Troisième graphique (bas gauche) concernant les variances des résidus pour chaque combinaison de niveau de démocratie et d'état sanitaire. Là aussi il est difficile de conclure à une variance constante des résidus avec le graphe car on peut discerner une légère forme constituée de 2 pentes. On va donc effectuer une test de *bartlett* :

```{r bartlett.test}
bartlett.test(residuals(lm1), interaction(democratie, sanitaire))
```
La p-value est très faible donc on rejet l'hypothèse nulle de variance constante des résidus. 

Sur le 4ème graphique (bas droite) on voit que les points 33, 35 et 38 se démarquent un peu plus que les autres, mais gardent une distance de Cook inférieure à 0.5, donc nous pouvons dire qu'il n'y a pas de valeur aberrante (outlier).

On peut également vérifier cette dernière hypothèse avec le plot suivant qui est peut être plus clair :

```{r cook}
par(mfrow=c(1,1))
plot(lm1,4)
```

En conclusion, ces hypothèses nous permettent de dire que le modèle linéaire lm1 n'est pas le modèle le plus adapté pour notre analyse. 

### Q8. On propose le code R ci-dessous. Expliquer ce qui est fait et comment peut-ont interpréter les 3 sorties numériques finales ?

```{r code q8}
F = matrix(0, nc = 4, nr = 1000)
for (i in 1:1000) {
  CO2_sim = sample(x = co2,
                   size = length(co2),
                   replace = FALSE)
  lm_temp = lm(CO2_sim ~ sanitaire * democratie)
  F[i, ] = anova(lm_temp)$"F value"
}
sum(F[, 1] > anova(lm1)$"F value"[1]) / 1000
sum(F[, 2] > anova(lm1)$"F value"[2]) / 1000
sum(F[, 3] > anova(lm1)$"F value"[3]) / 1000
```

Graphiquement cela donnerait :


```{r histo}
par(mfrow=c(1,3))
hist(F[,1], col = 4) ; abline(v = anova(lm1)$"F value"[1], col = 'red')
hist(F[, 2], col = 5) ; abline(v = anova(lm1)$"F value"[2], col = 'red')
hist(F[,3], col = 3) ; abline(v = anova(lm1)$"F value"[3], col = 'red')
```

Remarque : Sur les histogrammes on obtient des "formes" de loi de chisq2 ou loi de Fisher. Attention toutefois rien ne dit qu'il s'agit réellement de l'une ou l'autre de ces lois.

Avec ce code nous avons réalisé un test de simulation par rééchantillonnage et permutation. Nous avons fait 1000 simulations dans lesquelles nous avons permuté aléatoirement et sans remise les 114 mesures d'émissions de CO2. Ensuite nous avons réalisé 1000 modèles linaires *lm* semblable au modèle *lm1*, c'est à dire que nous retrouvons nos trois termes : (*sanitaire*, *democratie*, *sanitaire:democratie*). À chaque simulation nous stockons dans une matrice *F* (1000 par 4) les F-values issus des tests anova.

Les trois sorties comparent le nombre de fois sur les 1000 simulations où nous obtenons une F-value supérieure à celle des facteurs respectifs {1, 2, 3} dans le modèle lm1. Pour les facteurs 1 et 2 nous obtenons 0, cela se vérifie sur les histogrammes où l'on aperçois même pas la droite verticale correspondant à la F-value des facteurs pour un anova(lm1).

Pour le facteur 3 nous obtenons un score de 0.3 environ. Ces simulations visent à confirmer les effets globaux des facteurs *sanitaire* et *democratie*. En effet le fait d'avoir permuté les mesures de CO2 et les scores obtenus pour les facteurs 1 et 2 montrent bien qu'il existe un réel lien entre l'émission de CO2 et le niveau de démocratie du pays ainsi que l'état sanitaire de celui ci. L'interaction des deux facteurs quant à elle n'affecte pas ces mesures, c'est pour cela que nous avons une score pour le facteur (d'interaction) 3 proche de la p-value du *anova(lm1)*. 

### Q9. On se propose de transformer la variable CO2 en ln(CO2), refaire l’analyse avec la variable transformée et refaire les conclusions.

```{r q9}
logCO2 <- log(co2)
lm3 <- lm(logCO2 ~ democratie*sanitaire)
```

On vérifie rapidement les hypothèses associées à ce nouveau modèle lm3 (sans détailler ici)
```{r hypotheses lm3}
par(mfrow = c(2,2))
plot(lm3)
shapiro.test(residuals(lm3)) # on ne rejete pas H0
bartlett.test(residuals(lm3), democratie)
bartlett.test(residuals(lm3), sanitaire) # => on rejete H0
par(mfrow = c(1,1))
plot(lm3, 4)
```

A priori les résidus semblent cette fois ci suivre une loi normale d'espérance nulle. Cependant nous n'avons toujours pas d'homogénéité des variances. Le modèle est un peu plus adapté que lm1 mais le soucis d'homoscédasticité persiste. Les distances de Cooks sont également moins élevées ( > 0.10), les individus 2, 9 et 94 se démarquent des autres toute fois. .

```{r anova lm3}
anova(lm3)
```
D'après l'anova de *lm3*, les effets *democratie* et *sanitaire* sont encore plus significatifs qu'avec le modèle *lm1*.

```{r simulation avec logCO2}
Fb = matrix(0, nc = 4, nr = 1000)
for (i in 1:1000) {
  logCO2_sim = sample(x = logCO2,
                   size = length(logCO2),
                   replace = FALSE)
  lm_temp = lm(logCO2_sim ~ sanitaire * democratie)
  Fb[i, ] = anova(lm_temp)$"F value"
}
sum(Fb[, 1] > anova(lm3)$"F value"[1]) / 1000
sum(Fb[, 2] > anova(lm3)$"F value"[2]) / 1000
sum(Fb[, 3] > anova(lm3)$"F value"[3]) / 1000
```
En refaisant la simulation de rééchantillonnage mais avec cette fois - ci logCO2, on retombe sur les mêmes résultats, ce quiest cohérent avec l'anova fait juste au dessus.

### Q10. En fonction des différents modèles et des analyses réalisées jusque là, discuter de la robustesse de l’anova en fonction des conditions d’application du test.

Les conditions d'application du test d'anova sont les suivantes :

- Normalité de la distribution ;
- Il y a homoscedasticité des résidus, c'est à dire qu'ils ont la même variance quelque soit le groupe considéré.

Comme nous l'avons vu plus haut, ces hypothèses ne sont pas respectées pour nos différents modèles linéaires. Cependant, les modèles linéaires et tests anova sont assez **robustes** dès lors que nous avons un échantillon de taille suffisante. Ainsi leur résultats peuvent rester valables, il s'agit là d'une propriété asymptotique. 

Pour ce qui est de la normalité, une solution pourrait être comme nous l'avons fait en Q9, de passer par un logarithme, cela permet d'obtenir une distribution plus "symétrique". Une racine carrée aurait éventuellement pue être possible également. 

Pour l'hétéroscédasticité , une solution serait tout simplement de travailler sur un plan équilibré, cela atténuerait les effets de non homogénéité des variances.

### Q11. Les variables consommation d’eau et émission de CO2 sont-elles corrélées ?Faire un test paramétrique et un test non paramétrique et discuter de la différence de pvalue entre les deux tests.

Les tests paramétriques fonctionnent en supposant que les données que l’on a à disposition suivent un type de loi de distribution connu (en général la loi normale). Les tests non paramétriques ne font aucune hypothèse sur le type de loi de distribution des données. Ils se basent uniquement sur les propriétés numériques des échantillons.

Pour voir si nos variables eau et co2 sont corrélées nous pouvons utiliser le *cor.test*. Attention par défaut le *cor.test* utilise la méthode de "Pearson" qui fait l'hypothèse que notre échantillon suit une loi normale, c'est donc un test paramétrique. Nous pouvons donc faire une simulation par permutation afin de voir si nos variables suivent une loi normale :

```{r q11 norm}
library(nortest)

R <- rank(co2)
S <- rank(eau)
D <- sum((R-S)**2)

simulation=vector()
for (i in 1:1000) {
  R_sim=sample(R, length(R),replace=FALSE)
  S_sim=sample(S, length(S), replace = FALSE)
  simulation[i]=sum((R_sim - S_sim)**2)
}

hist(simulation, col = "aquamarine")
cvm.test(simulation)
```
L 'hypothèse que nos 2 variables *eau* et *co2* suivent une distribution normale est donc vérifiée, nous pouvons utiliser un test paramétrique :

```{r test param}
cor.test(co2, eau, m = "pearson")
```
Nous obtenons une p-value $<< 0.05$, ce coefficient de corrélation de Pearson est donc bien significatif, nous pouvons rejeter H0 et dire que les variables eau et co2 sont corrélées. 

Remarque : Comme nous avons utilisé plusieurs test ici, nous aurions pu utiliser une correction de Bonférroni.

Nous aurions également pu faire un modèle linéaire comme ci-dessous, il s'agit également d'un test paramétrique, on remarque que la p-value est la même que dans le *cor.test*.

```{r lm q11}
anova(lm(co2~ eau))
```

Pour ce qui est de tester la corrélation avec un test non paramétrique, nous allons également utiliser la fonction *cor.test* avec des coefficient non parametriques cette fois ci. On peut par exemple utiliser les coefficients de corrélation de Kendall ou de Spearman : 

```{r test non param}
cor.test(co2, eau,  m="spearman") # attention aux ex-aequos 
cor.test(co2, eau, m="kendall")
```
Les p-values sont très faibles dans les 2 tests, la corrélation est donc significative et nous pouvons rejeter H0 dans les 2 cas.

On observe que la p-value du test non-paramétrique est très inférieure à celle du test paramétrique. De façon générale, les tests paramétriques sont plus puissants que les test non-paramétriques, c'est à dire qu'ils seront plus apte à rejeter H0, si le rejet est justifié. En revanche, un test non paramétrique sera lui plus robuste qu'un test paramétrique, c'est à dire qu'il pourra être utilisé dans un plus grand nombre de situations.


On s'intéresse maintenant à la géographie des émissions de CO2, avec les variables continent (considérée comme fixe) et region_monde (considérée ici, pour les besoins de l'exercice, comme aléatoire).

### Q12. Décrire le plan d’expérience qui intègre les variables continent et region_monde pour expliquer les émissions de CO2 (la variable pays ne sera pas considérée ici).

```{r q12}
tab2 <- table(continent, region); tab2
```


À présent le plan d'expérience qui intègre les variables *continent*, *co2* et *region* est un plan d'expérience factoriel hiérarchisé : *region* est nichée dans *continent*. C'est un plan mixte : *region* est aléatoire (9 niveaux) et continent est fixe (4 niveaux). Il n'y a pas le même nombre de répétition par couple (continent[i], region[j]), c'est donc déséquilibré.


### Q13. Construire le modèle adéquate pour estimer la part de variabilité apportée par les pays et par les régions du monde, puis comparez globalement les différents continents. Donner ces valeurs et justifiez vos conclusions par les tests appropriés. Si les fonctions utilisées ne permettent pas d’obtenir des tests pour les effets fixes (manque de données), vous le préciserez sur votre copie et ne chercherez pas à faire d’autres analyses


Commençons par un modèle *lm* classique. La variable *region* étant nichée dans *continent*, nous les introduirons dans l'ordre décroissant (conteneur + contenu ) dans le modèle.

```{r lm classiques}
lm4 <- lm(co2 ~ continent + region) # attention l'ordre est important 
anova(lm4)
Anova(lm4, type = "II")
summary(lm4)
```
Avec ces tests d'anova nous ne pouvons regarder ici que le niveau du facteur niché, à savoir *region*. Ainsi il y a des différences très significatives entre les régions de façon globale.

Si l'on regarde les coefficients de *lm4* (avec le *summary()* ou la commande *coefficients()*), et en particulier ceux portés par la variable *region* (car c'est la seule qui a de l'intérêt ici) on voit tout d'abord que certains d'entre eux n'ont pas de valeur, peut être par manque de donnée. Par ailleurs, si l'on regarde les régions d'Amérique Latine et d'Europe de l'Est, celles-ci ont des coefficients négatifs. Cela signifie que l'écart de moyenne entre ces régions et celle mise en intercepte (par défaut ici c'est l'Afrique Subsaharienne) est négatif, donc que en moyenne l'émission de CO2 est plus élevée en Afrique Subsaharienne qu'en Amérique Latine ou qu'en Europe de l'Est. Toutefois cette interprétation manque de cohérence, de plus on voit dans le *summary()* que l'intercepte n'est pas du tout significatif. Il faudrait donc faire un contrast ici pour changer de région. 

```{r lm4 contrast}
region2 <- as.factor(region)
contrasts(region2) <- contr.treatment(9, base = 5) # Asie_indus en intercepte

lm4b <- lm(co2 ~ continent + region2) 
summary(lm4b)
```
Cette fois ci en ayant placé la région Asie_indus en intercepte, ce dernier est très significatif (p-value = 1.41e-11), cela va nous permettre de mieux comparer 2 à 2 les régions. Par exemple les régions Af_subsahar, Am_latine, Asie_Centrale, Asie_S_SE et Europe_Est on des coefficients négatifs. Cela signifie que leur différence de moyenne avec la région d'Asie_indus est négative, autrement dit que l'Asie industrielle émet plus de CO2 que ces régions là.

Maintenant essayons de regarder s'il existe un effet globale des continents. Pour cela nous allons construire un modèle qui affectera la variabilité expliquée par l'effet région avec l'erreur pure dans la résiduelle.


```{r aov lm5}
lm5 <- aov(co2 ~ continent + Error(region))
summary(lm5)
coefficients(lm5)
```
Ici on voit donc que l'effet continent n'est pas significatif sur l'émission de CO2 (p-value = 0.621). Par ailleurs la hiérarchisation de notre modèle coûte en puissance, ainsi la p-value du "niveau supérieur" est  beaucoup plus élevée. 

** Pour aller plus loin ** 

Comme le plan est mixte et hiérarchisé, nous allons utiliser des modèle des librairies *nlme* et *lme4*, ces derniers seront plus appropriés à notre cas de figure plutôt qu'un modèle *lm()* classique.

```{r libraries, message=FALSE}
library(nlme)
library(lme4)
``` 

```{r lm 6}
lm6 <- lme(fixed=co2~1+continent, random = list(continent=~1, region=~1))
summary(lm6)
```

Ici nous manquons de donner pour conclure à un effet fixe de *continent*. Essayons avec un dernier modèle :

```{r lm7}
lm7 <- lmer(co2~continent+(1|continent:region))
summary(lm7)
anova(lm7)
```
Ici nous avons la confirmation par l'anova que *continent* n'induit globalement aucun effet sur l'émission de CO2. Par ailleurs, dans le *summary()* on voit clairement qu'aucun des coefficients n'est significatif. L'Asie est cependant à la limite de la significativité (p-value = 0.09), finalement cela est plus ou moins cohérent avec ce que nous avons plus haut avec notre modèle *lm4b* lorsque nous avons placé la région d'Asie industrielle en intercepte.
